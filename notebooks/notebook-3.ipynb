{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.functional as F\n",
    "# import pytorch_lightning as pl\n",
    "\n",
    "# from torchrbpnet.layers import Conv1DFirstLayer, Conv1DResBlock, IndexEmbeddingOutputHead\n",
    "# from torchrbpnet.losses import MultinomialNLLLossFromLogits\n",
    "# from torchrbpnet.data.utils import TFIterableDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Network(nn.Module):\n",
    "#     def __init__(self, tasks, n_layers=9, n_body_filters=256):\n",
    "#         super(Network, self).__init__()\n",
    "\n",
    "#         self.tasks = tasks\n",
    "\n",
    "#         self.body = nn.Sequential(*[Conv1DFirstLayer(4, n_body_filters, 6)]+[(Conv1DResBlock(n_body_filters, n_body_filters, dilation=(2**i))) for i in range(n_layers)])\n",
    "#         self.head = IndexEmbeddingOutputHead(len(self.tasks), dims=n_body_filters)\n",
    "    \n",
    "#     def forward(self, inputs, **kwargs):\n",
    "#         x = inputs\n",
    "\n",
    "#         for layer in self.body:\n",
    "#             x = layer(x)\n",
    "\n",
    "#         return self.head(x)\n",
    "\n",
    "# network = Network(tasks=list(range(223)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MultiRBPNet(pl.LightningModule):\n",
    "#     def __init__(self, network):\n",
    "#         super().__init__()\n",
    "#         self.network = network # Network(tasks=range(223))\n",
    "#         self.loss_fn = MultinomialNLLLossFromLogits()\n",
    "\n",
    "#     def training_step(self, batch, **kwargs):\n",
    "#         x, y = batch\n",
    "#         y_pred = self.network(x)\n",
    "#         loss = self.loss_fn(y, y_pred, dim=-2)\n",
    "#         return loss\n",
    "\n",
    "#     def configure_optimizers(self):\n",
    "#         optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "#         return optimizer\n",
    "\n",
    "# model = MultiRBPNet(network)\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = TFIterableDataset('example-data-matrix/windows.chr13.4.data.matrix.filtered.tfrecord', shuffle=1_000_000)\n",
    "# dataloader = torch.utils.data.DataLoader(dataset, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marc/miniconda3/envs/torch/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import loggers as pl_loggers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-16 11:45:37.853049: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-16 11:45:38.701673: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-16 11:45:38.701722: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-16 11:45:38.701729: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-16 11:45:39.490637: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-16 11:45:39.491023: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-02-16 11:45:39.491083: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2023-02-16 11:45:39.491152: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-02-16 11:45:39.491205: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-02-16 11:45:39.491240: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "from torchrbpnet.data import tfrecord_to_dataloader, dummy_dataloader\n",
    "\n",
    "# dataloader = tfrecord_to_dataloader('example-data-matrix/windows.chr13.4.data.matrix.filtered.tfrecord')\n",
    "dataloader = dummy_dataloader(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrbpnet.networks import MultiRBPNet\n",
    "# from torchrbpnet.lightning import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Model(network=MultiRBPNet(tasks=list(range(223))))\n",
    "# model = Model(network=MultiRBPNet(tasks=list(range(7))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from torchrbpnet.losses import MultinomialNLLLossFromLogits\n",
    "from torchrbpnet.metrics import batched_pearson_corrcoef\n",
    "\n",
    "# %%\n",
    "class Model(pl.LightningModule):\n",
    "    def __init__(self, network):\n",
    "        super().__init__()\n",
    "        self.network = network\n",
    "        self.loss_fn = MultinomialNLLLossFromLogits()\n",
    "        # self.metrics = [batched_pearson_corrcoef] + [self.loss_fn]\n",
    "\n",
    "    def training_step(self, batch, *args, **kwargs):\n",
    "        x, y = batch\n",
    "        y_pred = self.network(x)\n",
    "        loss = self.loss_fn(y, y_pred, dim=-2)\n",
    "        metrics = self.compute_metrics(y, y_pred)\n",
    "        self.log_dict(metrics, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, *args, **kwargs):\n",
    "        x, y = batch\n",
    "        y_pred = self.network(x)\n",
    "        loss = self.loss_fn(y, y_pred, dim=-2)\n",
    "        metrics = self.compute_metrics(y, y_pred, suffix='_val')\n",
    "        self.log_dict(metrics, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    # def compute_metrics(self, y, y_pred, suffix=''):\n",
    "    #     metric_results = {f'{metric.__name__}' + suffix: metric(y, y_pred) for metric in self.metrics}\n",
    "    #     return metric_results\n",
    "\n",
    "    def compute_metrics(self, y, y_pred, suffix=''):\n",
    "        pccs = batched_pearson_corrcoef(y, y_pred)\n",
    "        return {'pcc_mean'+suffix: torch.mean(pccs), 'pcc_std'+suffix: torch.std(pccs)}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "model = Model(network=MultiRBPNet(tasks=list(range(7))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning import loggers as pl_loggers\n",
    "\n",
    "loggers = [\n",
    "    pl_loggers.TensorBoardLogger('logs/tensorboard/'),\n",
    "    pl_loggers.CSVLogger('logs/csv/'),\n",
    "]\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=5, logger=loggers)\n",
    "trainer.fit(model=model, train_dataloaders=dataloader, val_dataloaders=dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7c2a629b5d736a8b2a3c0111829bdedfa4bd0b48e49067d38bd73bb54a8250f9"
  },
  "kernelspec": {
   "display_name": "Python 3.10.9 ('torch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
